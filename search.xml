<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>yolo5-train</title>
      <link href="/2020/08/20/yolo5-train/"/>
      <url>/2020/08/20/yolo5-train/</url>
      
        <content type="html"><![CDATA[<h1 id="YOLOv5自定义数据集训练"><a href="#YOLOv5自定义数据集训练" class="headerlink" title="YOLOv5自定义数据集训练"></a>YOLOv5自定义数据集训练</h1><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>本文介绍如何在自己的VOC格式数据集上训练YOLO5目标检测模型。</p><h2 id="VOC数据集格式"><a href="#VOC数据集格式" class="headerlink" title="VOC数据集格式"></a>VOC数据集格式</h2><p>首先，先来了解一下<a href="http://host.robots.ox.ac.uk/pascal/VOC/">Pascal VOC数据集</a>的格式，该数据集油5个部分组成，文件组织结构如下，目前主要的是VOC2007和VOC2012.</p><pre><code>- VOC    - JPEGImages        - 1.jpg        - 2.jpg        - ...    - Annotations        - 1.xml        - 2.xml        - ...    - ImageSets        - Main            - train.txt            - val.txt            - test.txt            - trainval.txt        - ...    - SegmentationClass    - SegmentationObject</code></pre><p>第一个文件夹<strong>JPEGImages</strong>为所有的图像，也就是说，训练集、验证集和测试集需要自己划分；<strong>Annotations</strong>为JPEGImages文件夹中每个图片对应的标注，xml格式文件，文件名与对应图像相同；<strong>ImageSets</strong>主要的子文件夹为Main，其中有四个文本文件，为训练集、验证集、测试集和训练验证集的图片文件名；<strong>SegmentationClass</strong>和<strong>SegmentationObject</strong>文件夹存放分割的结果图，前者为语义分割，后者为实例分割。</p><p>上述xml标注文件，格式如下。对其具体标注解释。</p><pre class=" language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>annotation</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>folder</span><span class="token punctuation">></span></span>down<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>folder</span><span class="token punctuation">></span></span> # 图片所处文件夹  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>filename</span><span class="token punctuation">></span></span>1.jpg<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>filename</span><span class="token punctuation">></span></span> # 图片文件名及后缀  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>path</span><span class="token punctuation">></span></span>./savePicture/train_29635.jpg<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>path</span><span class="token punctuation">></span></span> # 存放路径  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>source</span><span class="token punctuation">></span></span>  #图源信息    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>database</span><span class="token punctuation">></span></span>Unknown<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>database</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>source</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>size</span><span class="token punctuation">></span></span> # 图片尺寸和通道    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>width</span><span class="token punctuation">></span></span>640<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>width</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>height</span><span class="token punctuation">></span></span>480<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>height</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>depth</span><span class="token punctuation">></span></span>3<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>depth</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>size</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>segmented</span><span class="token punctuation">></span></span>0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>segmented</span><span class="token punctuation">></span></span>  #是否有分割label，0无1有  # 图像中包含的所有目标，一个目标一个object标签  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>object</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>car<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>  # 目标类别    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>pose</span><span class="token punctuation">></span></span>Unspecified<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>pose</span><span class="token punctuation">></span></span>  # 目标的姿态    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>truncated</span><span class="token punctuation">></span></span>0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>truncated</span><span class="token punctuation">></span></span>  # 目标是否被部分遮挡（>15%）    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>difficult</span><span class="token punctuation">></span></span>0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>difficult</span><span class="token punctuation">></span></span>  # 是否为难以辨识的目标， 需要结合背景才能判断出类别的物体    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>bndbox</span><span class="token punctuation">></span></span>  # 目标边界框信息      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>xmin</span><span class="token punctuation">></span></span>2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>xmin</span><span class="token punctuation">></span></span>      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>ymin</span><span class="token punctuation">></span></span>156<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>ymin</span><span class="token punctuation">></span></span>      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>xmax</span><span class="token punctuation">></span></span>111<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>xmax</span><span class="token punctuation">></span></span>      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>ymax</span><span class="token punctuation">></span></span>259<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>ymax</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>bndbox</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>object</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>object</span><span class="token punctuation">></span></span>      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>multi_signs<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>editType</span> <span class="token punctuation">/></span></span>      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>pose</span><span class="token punctuation">></span></span>Unspecified<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>pose</span><span class="token punctuation">></span></span>      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>truncated</span><span class="token punctuation">></span></span>0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>truncated</span><span class="token punctuation">></span></span>      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>difficult</span><span class="token punctuation">></span></span>0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>difficult</span><span class="token punctuation">></span></span>      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>bndbox</span><span class="token punctuation">></span></span>         <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>xmin</span><span class="token punctuation">></span></span>81<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>xmin</span><span class="token punctuation">></span></span>         <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>ymin</span><span class="token punctuation">></span></span>98<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>ymin</span><span class="token punctuation">></span></span>         <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>xmax</span><span class="token punctuation">></span></span>154<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>xmax</span><span class="token punctuation">></span></span>         <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>ymax</span><span class="token punctuation">></span></span>243<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>ymax</span><span class="token punctuation">></span></span>      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>bndbox</span><span class="token punctuation">></span></span>   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>object</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>annotation</span><span class="token punctuation">></span></span></code></pre><p><strong>也就是说，遇到这种文件格式的数据（主要特点为图像全放在一个文件夹，标注格式如上等），将其作为VOC格式的数据集，将自己的数据集重构为VOC格式以便开源项目的处理。</strong></p><h2 id="自定义训练"><a href="#自定义训练" class="headerlink" title="自定义训练"></a>自定义训练</h2><h3 id="下载源码"><a href="#下载源码" class="headerlink" title="下载源码"></a><strong>下载源码</strong></h3><p>通过<code>git clone git@github.com:ultralytics/yolov5.git</code>将YOLOv5源码下载到本地，本文后面的内容也可以参考<a href="https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data">官方的自定义数据集训练教程</a>，不同于我的教程，该教程全面包含了VOC格式和COCO格式数据集的处理方法。</p><p>此时创建虚拟环境，并通过<code>pip install -r requirements.txt</code>安装依赖包，我这里测试过，最新的项目是兼容Pytorch 1.6的，1.6之前的Pytorch会有一些问题。</p><h3 id="数据集处理"><a href="#数据集处理" class="headerlink" title="数据集处理"></a><strong>数据集处理</strong></h3><p>一般，符合VOC格式的数据集至少包含图像和标注两个文件夹，结构如下。我这里假定测试集是独立的，该数据集实际上为训练集，只需要划分出训练集和验证集即可。<strong>这里建议将文件夹重命名如下，否则后续可能出现数据集加载失败的情况。</strong></p><pre><code>- 根目录    - images    - Annotations</code></pre><p>下面，编写脚本划分数据集，<code>split_train_val.py</code>脚本内容如下（参考Github上的开源脚本），只需要执行<code>python split_train_val.py --xml_path dataset_root/Annotations/ --txt_path dataset_root/anno_txt/</code>就得到了划分结果的文件列表，如训练集对应的<code>train.txt</code>如下图，里面与训练图片所有的文件名。</p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> os<span class="token keyword">import</span> random<span class="token keyword">import</span> argparseparser <span class="token operator">=</span> argparse<span class="token punctuation">.</span>ArgumentParser<span class="token punctuation">(</span><span class="token punctuation">)</span>parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--xml_path'</span><span class="token punctuation">,</span> type<span class="token operator">=</span>str<span class="token punctuation">,</span> help<span class="token operator">=</span><span class="token string">'input xml label path'</span><span class="token punctuation">)</span>parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--txt_path'</span><span class="token punctuation">,</span> type<span class="token operator">=</span>str<span class="token punctuation">,</span> help<span class="token operator">=</span><span class="token string">'output txt label path'</span><span class="token punctuation">)</span>opt <span class="token operator">=</span> parser<span class="token punctuation">.</span>parse_args<span class="token punctuation">(</span><span class="token punctuation">)</span>trainval_percent <span class="token operator">=</span> <span class="token number">1.0</span>train_percent <span class="token operator">=</span> <span class="token number">0.8</span>xmlfilepath <span class="token operator">=</span> opt<span class="token punctuation">.</span>xml_pathtxtsavepath <span class="token operator">=</span> opt<span class="token punctuation">.</span>txt_pathtotal_xml <span class="token operator">=</span> os<span class="token punctuation">.</span>listdir<span class="token punctuation">(</span>xmlfilepath<span class="token punctuation">)</span><span class="token keyword">if</span> <span class="token operator">not</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span>txtsavepath<span class="token punctuation">)</span><span class="token punctuation">:</span>    os<span class="token punctuation">.</span>makedirs<span class="token punctuation">(</span>txtsavepath<span class="token punctuation">)</span>num <span class="token operator">=</span> len<span class="token punctuation">(</span>total_xml<span class="token punctuation">)</span>list_index <span class="token operator">=</span> range<span class="token punctuation">(</span>num<span class="token punctuation">)</span>tv <span class="token operator">=</span> int<span class="token punctuation">(</span>num <span class="token operator">*</span> trainval_percent<span class="token punctuation">)</span>tr <span class="token operator">=</span> int<span class="token punctuation">(</span>tv <span class="token operator">*</span> train_percent<span class="token punctuation">)</span>trainval <span class="token operator">=</span> random<span class="token punctuation">.</span>sample<span class="token punctuation">(</span>list_index<span class="token punctuation">,</span> tv<span class="token punctuation">)</span>train <span class="token operator">=</span> random<span class="token punctuation">.</span>sample<span class="token punctuation">(</span>trainval<span class="token punctuation">,</span> tr<span class="token punctuation">)</span>file_trainval <span class="token operator">=</span> open<span class="token punctuation">(</span>txtsavepath <span class="token operator">+</span> <span class="token string">'/trainval.txt'</span><span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">)</span>file_test <span class="token operator">=</span> open<span class="token punctuation">(</span>txtsavepath <span class="token operator">+</span> <span class="token string">'/test.txt'</span><span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">)</span>file_train <span class="token operator">=</span> open<span class="token punctuation">(</span>txtsavepath <span class="token operator">+</span> <span class="token string">'/train.txt'</span><span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">)</span>file_val <span class="token operator">=</span> open<span class="token punctuation">(</span>txtsavepath <span class="token operator">+</span> <span class="token string">'/val.txt'</span><span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">)</span><span class="token keyword">for</span> i <span class="token keyword">in</span> list_index<span class="token punctuation">:</span>    name <span class="token operator">=</span> total_xml<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token string">'\n'</span>    <span class="token keyword">if</span> i <span class="token keyword">in</span> trainval<span class="token punctuation">:</span>        file_trainval<span class="token punctuation">.</span>write<span class="token punctuation">(</span>name<span class="token punctuation">)</span>        <span class="token keyword">if</span> i <span class="token keyword">in</span> train<span class="token punctuation">:</span>            file_train<span class="token punctuation">.</span>write<span class="token punctuation">(</span>name<span class="token punctuation">)</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            file_val<span class="token punctuation">.</span>write<span class="token punctuation">(</span>name<span class="token punctuation">)</span>    <span class="token keyword">else</span><span class="token punctuation">:</span>        file_test<span class="token punctuation">.</span>write<span class="token punctuation">(</span>name<span class="token punctuation">)</span>file_trainval<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>file_train<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>file_val<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>file_test<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><p><img src="https://i.loli.net/2020/08/20/HY5yUEdALgmVthw.png"></p><p>接下来，我们要做的就是每个xml标注提取bbox信息为txt格式，每个图像对应一个txt文件，文件每一行为一个目标的信息，包括<code>类别 xmin xmax ymin ymax</code>。使用的脚本<code>voc_label.py</code>内容如下（<strong>注意，类别要替换为当前数据集的类别列表</strong>），<strong>在数据集根目录（此时包含Annotations、anno_txt以及images三个文件夹的目录）下执行该脚本</strong>，如<code>python ../../utils/voc_label.py</code>。</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># -*- coding: utf-8 -*-</span><span class="token keyword">import</span> xml<span class="token punctuation">.</span>etree<span class="token punctuation">.</span>ElementTree <span class="token keyword">as</span> ET<span class="token keyword">import</span> os<span class="token keyword">from</span> os <span class="token keyword">import</span> getcwdsets <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">,</span> <span class="token string">'val'</span><span class="token punctuation">,</span> <span class="token string">'test'</span><span class="token punctuation">]</span>classes <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'window_shielding'</span><span class="token punctuation">,</span> <span class="token string">'multi_signs'</span><span class="token punctuation">,</span> <span class="token string">'non_traffic_signs'</span><span class="token punctuation">]</span>abs_path <span class="token operator">=</span> os<span class="token punctuation">.</span>getcwd<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">convert</span><span class="token punctuation">(</span>size<span class="token punctuation">,</span> box<span class="token punctuation">)</span><span class="token punctuation">:</span>    dw <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">.</span> <span class="token operator">/</span> <span class="token punctuation">(</span>size<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    dh <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">.</span> <span class="token operator">/</span> <span class="token punctuation">(</span>size<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    x <span class="token operator">=</span> <span class="token punctuation">(</span>box<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">+</span> box<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">2.0</span> <span class="token operator">-</span> <span class="token number">1</span>    y <span class="token operator">=</span> <span class="token punctuation">(</span>box<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">+</span> box<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">2.0</span> <span class="token operator">-</span> <span class="token number">1</span>    w <span class="token operator">=</span> box<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">-</span> box<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>    h <span class="token operator">=</span> box<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span> <span class="token operator">-</span> box<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span>    x <span class="token operator">=</span> x <span class="token operator">*</span> dw    w <span class="token operator">=</span> w <span class="token operator">*</span> dw    y <span class="token operator">=</span> y <span class="token operator">*</span> dh    h <span class="token operator">=</span> h <span class="token operator">*</span> dh    <span class="token keyword">return</span> x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> w<span class="token punctuation">,</span> h<span class="token keyword">def</span> <span class="token function">convert_annotation</span><span class="token punctuation">(</span>image_id<span class="token punctuation">)</span><span class="token punctuation">:</span>    in_file <span class="token operator">=</span> open<span class="token punctuation">(</span><span class="token string">'Annotations/%s.xml'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>image_id<span class="token punctuation">)</span><span class="token punctuation">)</span>    out_file <span class="token operator">=</span> open<span class="token punctuation">(</span><span class="token string">'labels/%s.txt'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>image_id<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">)</span>    tree <span class="token operator">=</span> ET<span class="token punctuation">.</span>parse<span class="token punctuation">(</span>in_file<span class="token punctuation">)</span>    root <span class="token operator">=</span> tree<span class="token punctuation">.</span>getroot<span class="token punctuation">(</span><span class="token punctuation">)</span>    size <span class="token operator">=</span> root<span class="token punctuation">.</span>find<span class="token punctuation">(</span><span class="token string">'size'</span><span class="token punctuation">)</span>    w <span class="token operator">=</span> int<span class="token punctuation">(</span>size<span class="token punctuation">.</span>find<span class="token punctuation">(</span><span class="token string">'width'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>text<span class="token punctuation">)</span>    h <span class="token operator">=</span> int<span class="token punctuation">(</span>size<span class="token punctuation">.</span>find<span class="token punctuation">(</span><span class="token string">'height'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>text<span class="token punctuation">)</span>    <span class="token keyword">for</span> obj <span class="token keyword">in</span> root<span class="token punctuation">.</span>iter<span class="token punctuation">(</span><span class="token string">'object'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        difficult <span class="token operator">=</span> obj<span class="token punctuation">.</span>find<span class="token punctuation">(</span><span class="token string">'difficult'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>text        cls <span class="token operator">=</span> obj<span class="token punctuation">.</span>find<span class="token punctuation">(</span><span class="token string">'name'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>text        <span class="token keyword">if</span> cls <span class="token operator">not</span> <span class="token keyword">in</span> classes <span class="token operator">or</span> int<span class="token punctuation">(</span>difficult<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">:</span>            <span class="token keyword">continue</span>        cls_id <span class="token operator">=</span> classes<span class="token punctuation">.</span>index<span class="token punctuation">(</span>cls<span class="token punctuation">)</span>        xmlbox <span class="token operator">=</span> obj<span class="token punctuation">.</span>find<span class="token punctuation">(</span><span class="token string">'bndbox'</span><span class="token punctuation">)</span>        b <span class="token operator">=</span> <span class="token punctuation">(</span>float<span class="token punctuation">(</span>xmlbox<span class="token punctuation">.</span>find<span class="token punctuation">(</span><span class="token string">'xmin'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>text<span class="token punctuation">)</span><span class="token punctuation">,</span> float<span class="token punctuation">(</span>xmlbox<span class="token punctuation">.</span>find<span class="token punctuation">(</span><span class="token string">'xmax'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>text<span class="token punctuation">)</span><span class="token punctuation">,</span> float<span class="token punctuation">(</span>xmlbox<span class="token punctuation">.</span>find<span class="token punctuation">(</span><span class="token string">'ymin'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>text<span class="token punctuation">)</span><span class="token punctuation">,</span>             float<span class="token punctuation">(</span>xmlbox<span class="token punctuation">.</span>find<span class="token punctuation">(</span><span class="token string">'ymax'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>text<span class="token punctuation">)</span><span class="token punctuation">)</span>        b1<span class="token punctuation">,</span> b2<span class="token punctuation">,</span> b3<span class="token punctuation">,</span> b4 <span class="token operator">=</span> b        <span class="token comment" spellcheck="true"># 标注越界修正</span>        <span class="token keyword">if</span> b2 <span class="token operator">></span> w<span class="token punctuation">:</span>            b2 <span class="token operator">=</span> w        <span class="token keyword">if</span> b4 <span class="token operator">></span> h<span class="token punctuation">:</span>            b4 <span class="token operator">=</span> h        b <span class="token operator">=</span> <span class="token punctuation">(</span>b1<span class="token punctuation">,</span> b2<span class="token punctuation">,</span> b3<span class="token punctuation">,</span> b4<span class="token punctuation">)</span>        bb <span class="token operator">=</span> convert<span class="token punctuation">(</span><span class="token punctuation">(</span>w<span class="token punctuation">,</span> h<span class="token punctuation">)</span><span class="token punctuation">,</span> b<span class="token punctuation">)</span>        out_file<span class="token punctuation">.</span>write<span class="token punctuation">(</span>str<span class="token punctuation">(</span>cls_id<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">" "</span> <span class="token operator">+</span> <span class="token string">" "</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token punctuation">[</span>str<span class="token punctuation">(</span>a<span class="token punctuation">)</span> <span class="token keyword">for</span> a <span class="token keyword">in</span> bb<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">'\n'</span><span class="token punctuation">)</span>wd <span class="token operator">=</span> getcwd<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">for</span> image_set <span class="token keyword">in</span> sets<span class="token punctuation">:</span>    <span class="token keyword">if</span> <span class="token operator">not</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span><span class="token string">'labels/'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        os<span class="token punctuation">.</span>makedirs<span class="token punctuation">(</span><span class="token string">'labels/'</span><span class="token punctuation">)</span>    image_ids <span class="token operator">=</span> open<span class="token punctuation">(</span><span class="token string">'anno_txt/%s.txt'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>image_set<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span>    list_file <span class="token operator">=</span> open<span class="token punctuation">(</span><span class="token string">'%s.txt'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>image_set<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> image_id <span class="token keyword">in</span> image_ids<span class="token punctuation">:</span>        list_file<span class="token punctuation">.</span>write<span class="token punctuation">(</span>abs_path <span class="token operator">+</span> <span class="token string">'/images/%s.jpg\n'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>image_id<span class="token punctuation">)</span><span class="token punctuation">)</span>        convert_annotation<span class="token punctuation">(</span>image_id<span class="token punctuation">)</span>    list_file<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><p>这时候，我们的目标检测数据集就构建完成了，其内容如下，其中labels中为不同图像的标注文件，<code>train.txt</code>等几个根目录下的txt文件为划分后图像所在位置的绝对路径，如<code>train.txt</code>就含有所有训练集图像的绝对路径。</p><p><img src="https://i.loli.net/2020/08/20/NPwkyM3o4T2cn9m.png"></p><h3 id="配置文件"><a href="#配置文件" class="headerlink" title="配置文件"></a>配置文件</h3><p>下面需要两个配置文件用于模型的训练，一个用于数据集的配置，一个用于模型的配置。</p><p>首先是数据集的配置，在根目录下的data目录下新建一个yaml文件，内容如下，首先是训练集和验证集的划分文件，这个文件在上面一节最后生成得到了，然后是目标的类别数目和具体类别列表，这个列表务必和上一节最后<code>voc_label.py</code>中的一致。</p><pre class=" language-yaml"><code class="language-yaml"><span class="token key atrule">train</span><span class="token punctuation">:</span> dataset/train.txt<span class="token key atrule">val</span><span class="token punctuation">:</span> dataset/val.txt<span class="token comment" spellcheck="true"># number of classes</span><span class="token key atrule">nc</span><span class="token punctuation">:</span> <span class="token number">3</span><span class="token comment" spellcheck="true"># class names</span><span class="token key atrule">names</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'window_shielding'</span><span class="token punctuation">,</span> <span class="token string">'multi_signs'</span><span class="token punctuation">,</span> <span class="token string">'non_traffic_signs'</span><span class="token punctuation">]</span></code></pre><p>然后，编辑模型的配置文件，此时需要先在项目根目录下的weights目录下执行其中的download_weights.sh这个shell脚本来下载四种模型的权重。然后，选择一个模型，编辑项目根目录下models目录中选择的模型的配置文件，将第一个参数nc改为自己的数据集类别数即可，例如我使用yolov5x模型，则修改yolov5x.yaml文件。<strong>这里weights的下载可能因为网络而难以进行，我也将其上传到了百度网盘，<a href="%E9%93%BE%E6%8E%A5%EF%BC%9Ahttps://pan.baidu.com/s/1UQX6URxaJP0ZqALvWpDWkA">地址</a>给出，提取码为vjlx。</strong></p><p>#3# 模型训练</p><p>此时，可以使用下面的命令进行模型的训练，训练日志默认保存在<code>./runs/</code>下，包括模型参数、Tensorboard记录等。此时TensorBoard以已经默认打开，浏览器访问效果如下图（由于数据量很小，很快过拟合）。</p><pre class=" language-shell"><code class="language-shell">python train.py --img 640 --batch 8 --epoch 300 --data ./data/ads.yaml --cfg ./models/yolov5x.yaml --weights weights/yolov5x.pt --device '0'</code></pre><p><img src="https://i.loli.net/2020/08/20/GrLI9OTtZD3fJFH.png"></p><h3 id="模型测试"><a href="#模型测试" class="headerlink" title="模型测试"></a>模型测试</h3><p>最后，测试模型，使用下面的命令（该命令中<code>save-txt</code>选项用于生成结果的txt标注文件，不指定则只会生成结果图像）。其中，weights使用最满意的实验即可，source则提供一个包含所有测试图片的文件夹即可。</p><pre class=" language-shell"><code class="language-shell"> python detect.py --weights runs/exp0/weights/best.pt --source ./dataset/test/ --device 0 --save-txt</code></pre><p>这样，对每个测试图片会在默认的<code>inference/output</code>文件夹中生成一个同名的txt文件，按照我的需求修改了<code>detect.py</code>文件后，每个txt会生成一行一个目标的信息，信息包括<code>类别序号 置信度 xcenter ycenter w h</code>，后面四个为bbox位置，均未归一化。如下图。</p><p><img src="https://i.loli.net/2020/08/20/l86zj2dw9xHnTFO.png"></p><p>我这里因为是一个比赛，再将这个txt处理为了json文件。<strong>不论是这里的处理代码还是上面对<code>detec.py</code>修改的代码，都可以在文末给出的Github仓库找到。</strong></p><h2 id="补充说明"><a href="#补充说明" class="headerlink" title="补充说明"></a>补充说明</h2><p>本文介绍了如何使用YOLOv5在自己的数据集上进行训练，按部就班地进行了讲解。该项目在YOLOv5地源码基础上修改完成，代码开源于我的Github，欢迎star或者fork。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 目标检测 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> yolov5自定义数据集训练 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>anchor-free detection</title>
      <link href="/2020/08/20/anchor-free-detection/"/>
      <url>/2020/08/20/anchor-free-detection/</url>
      
        <content type="html"><![CDATA[<h1 id="Anchor-free目标检测"><a href="#Anchor-free目标检测" class="headerlink" title="Anchor-free目标检测"></a>Anchor-free目标检测</h1><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>沿着two-step到one-step，anchor-based到anchor-free的发展路线，如今，目标检测（Object Detection，OD）已经进入anchor-free的时代。这些anchor-free方法因为适用于多目标跟踪等领域，也促使了MOT的飞速发展。本文将沿着anchor-free目标检测发展地路线，简单介绍一下主要地一些方法思路，包括目前关注度较大地<strong>FCOS</strong>和<strong>CenterNet</strong>。</p><h2 id="何为anchor"><a href="#何为anchor" class="headerlink" title="何为anchor"></a>何为anchor</h2><p>在了解anchor-free的方法前，我们得知道什么是anchor，在过去，目标检测通常被建模为对候选框的分类和回归，不过，按照候选区域的产生方式不同，分为二阶段（two-step）检测和单阶段（one-step）检测，前者的候选框通过RPN（区域推荐网络）网络产生proposal，后者通过滑窗产生anchor。</p><p><img src="https://i.loli.net/2020/08/20/keLHXrlPFBnqjAf.png"></p><p>本文所提到的anchor-free方法则通过完全不同的思路解决目标检测问题，这些思路都没有采用预定义的候选框的概念。这两年，从CornerNet开始，anchor-free的目标检测框架层出不穷，宣告着目标检测迈入anchor-free时代。</p><h2 id="anchor-free发展"><a href="#anchor-free发展" class="headerlink" title="anchor-free发展"></a>anchor-free发展</h2><p>其实anchor-free不是一个很新的概念，最早可以追溯到YOLO算法，这应该是最早的anchor-free模型，而最近的anchor-free方法主要分为<strong>基于密集预测</strong>和<strong>基于关键点估计</strong>两种。</p><h3 id="早期研究"><a href="#早期研究" class="headerlink" title="早期研究"></a>早期研究</h3><p>先是聊一聊目标检测比较古老的研究，分别是Densebox和YOLO，前者发表于2015年9月，后者则开源于2016年。</p><p><strong>Densebox</strong></p><p>首先来聊一聊Densebox，这是地平线的算法工程师黄李超于2015年设计的一个端到端检测框架，对此有专门的<a href="https://zhuanlan.zhihu.com/p/24350950">文章</a>介绍。Densebox是深度学习用于目标检测的开山之作之一，当时已经有不错效果的R-CNN不够直接且高效，因而Densebox作者从OverFeat方法上得到启发：在图像上进行卷积等同于使用滑窗分类，为何不能使用全卷积对整个图像进行目标检测呢？</p><p><img src="https://i.loli.net/2020/08/20/fMqbOVpkK1rFSsE.png"></p><p>在这个基础上，设计了一套端到端的多任务全卷积模型，如上图所示。该模型可以直接回归出目标出现的置信度和相对位置，同时为了处理遮挡和小目标，引入上采用层融合浅层网络特征，得到更大的尺寸的输出特征图。下图是网络的输入和输出，对每个像素会得到一个5维向量，表示分类置信度和bbox到该pixel的四个距离。</p><p><img src="https://i.loli.net/2020/08/20/sZfUd1VOzECyGXv.png"></p><p>Densebox的主要贡献有两个：证明了单FCN（全卷积网络）可以实现检测遮挡和不同尺度的目标；在FCN结构中添加少量层引入landmark localization，将landmark heatmap和score map融合能够进一步提高检测性能。</p><p><strong>遗憾的是，当时目标检测的学者们沿着RCNN铺好的路亦步亦趋，现在想想，如果当时，就有足够多的关注给与Densebox，今天的目标检测是否会是全新的局面呢？</strong></p><p><strong>YOLO</strong></p><p>2016年开源的YOLOv1算法，是目前工业界比较关注的算法之一，它开创性地将目标检测中的候选框生成和目标识别通过一步完成，因而论文名为“You only look once”，YOLO模型可以直接从整个图像上得到边界框和对应的置信度。比较详细的理解可以参考<a href="https://zhouchen.blog.csdn.net/article/details/105178437">我之前YOLO算法的文章</a>。</p><p><img src="https://i.loli.net/2020/08/20/whpbPxLcqWmsytH.png"></p><p>YOLO的最大创新就是速度快，一方面将候选框生成的步骤去除，另一方面，通过多个网格负责目标的检测，大大加快运行速度。</p><blockquote><p>Densebox和YOLO很类似，都可以理解为单阶段检测，不过前者为密集预测，针对每个像素进行预测；后者针对划分得到的网格进行预测。同时，作为anchor-free的两篇开山之作，它们为后来的anchor-free检测提供了很多的思路。</p></blockquote><h3 id="基于密集预测"><a href="#基于密集预测" class="headerlink" title="基于密集预测"></a>基于密集预测</h3><p>沿着上一节YOLO和Densebox的思路，2019年出现了很多以此为基础的目标检测方法，包括FCOS、FSAF以及FoveaBox等等方法。</p><p><strong>FCOS</strong></p><p>这是这两年受到广泛的关注的目标检测算法，一方面它确实是anchor-free系列打破anchor-based精度神话的关键之作，另一方面，业界对这种单阶段高效算法有着巨大的需求。</p><p><img src="https://i.loli.net/2020/08/20/UVEgZsIvuQtBPTm.png"></p><p>上图是FCOS的pipeline设计图，核心的就是一个特征金字塔和三分支头网络，通过backbone之后对feature map上每一个点进行回归预测，和以往目标检测任务不同的是，<strong>除了分类和回归分支，加入了center-ness以剔除低质量预测，它和分类分支的乘积为最终的置信度。</strong></p><p>FCOS创新点如下:</p><ol><li>突破基于Faster-RCNN修补的思路，开创性地不使用anchor而是直接对每个像素进行预测，并在效果是远超Faster-RCNN。这主要是考虑到anchor地存在会带来大量地超参数，如anchor number等，而且这些anchor要计算和GT地IOU，也是很消耗算力的。</li><li>由于是像素级别的密集预测，因此可以使用分割任务的一些trick并且通过修改目标分支可用于实例分割和关键点检测等任务。</li><li>由于是全卷积网络，拥有很多FCN任务的优势，也可以借用其思想。</li></ol><p><strong>FSAF</strong></p><p><img src="https://i.loli.net/2020/08/20/j6QLvatzU9DmlBn.png"></p><p>这是一个针对FPN的优化思路，提出FSAF模块，让网络自己学习anchor适配。​在RetinaNet的基础上，FSAF模块引入了2个额外的卷积层，这两个卷积层各自负责anchor-free分支的分类和回归预测。此外，提出了在线特征选择策略，​实例输入到特征金字塔的所有层，然后求得所有anchor-free分支focal loss和IoU loss的和，选择loss最小的特征层来学习实例。训练时，特征根据安排的实例进行更新。推理时，不需要进行特征更新，因为最合适的特征金字塔层必然输出高置信分数。</p><blockquote><p>虽然都是基于密集预测，但相比于YOLO和Densebox，FCOS和FSAF使用FPN进行多尺度预测，此前的方法只有单尺度预测；不过，相比于YOLO这个单分支模型，其他方法都是通过两个子网络来进行分类和回归。</p></blockquote><h3 id="基于关键点估计"><a href="#基于关键点估计" class="headerlink" title="基于关键点估计"></a>基于关键点估计</h3><p>不同于密集预测的思路，以关键点估计为手段，目标检测出现了一条全新的主线，它彻底抛开了区域分类回归思想，主要出现了CornerNet、ExtremeNet以及集大成者的CenterNet，由于有两篇目标检测的文章网络名都是CenterNet，这里特指的是关注度比较高的Objects as points这篇文章。</p><p><strong>CornerNet</strong></p><p>这篇文章是后来很多基于关键点估计处理目标检测的算法基础，它开创性地用一对角点来检测目标。对一幅图像，预测两组heatmap，一组为top-left角点，另一组为bottom-right角点，每组heatmap有类别个通道。下图为框架图。</p><p><img src="https://i.loli.net/2020/08/20/1SjiLUVbJGzXr9o.png"></p><p><strong>ExtremeNet</strong></p><p>不同于CornerNet使用角点检测目标，ExtremeNet通过极值点和中心点来检测目标，这应该是最大地区别，其他一些关键点估计方面地细节，这里不多提。</p><p><img src="https://i.loli.net/2020/08/20/QuToZCtJUprdxwX.png"></p><p><strong>CenterNet</strong></p><p>下面来看看关键点估计用于目标检测地集大成者，CenterNet。抛开了传统的边框目标表示方法，将目标检测视为对一个点进行的关键点估计问题。相比较于基于bbox的方法，该模型端到端可微，其简单高效且实时性高。在主流地OD数据集上超越了大部分SOTA方法，且论文称在速度上超越了YOLO3。</p><p><img src="https://i.loli.net/2020/08/20/CIp6humX5QG9dPN.png"></p><p>通过中心点来表示目标，然后在中心点位置回归出目标的其他属性，这样，目标检测问题变成了一个关键点估计问题。只需要将图像传入全卷积网络，得到热力图，热力图的峰值点就是中心点。这里可以把中心点看做形状未知的锚点。但是该锚点只在位置上，没有尺寸框，没有阈值进行前后景分类；每个目标只会有一个正的锚点，因此不会用到NMS；而且，CenterNet与传统目标检测相比，下采样倍数较低，不需要多重特征图。</p><h2 id="发展思路"><a href="#发展思路" class="headerlink" title="发展思路"></a>发展思路</h2><h3 id="成功原因"><a href="#成功原因" class="headerlink" title="成功原因"></a>成功原因</h3><p>anchor-free能在精度上追赶上anchor-based方法，最大地原因应该归属上面绝大多数方法避不开地FPN（特征金字塔网络），因为在每个位置只预测一个框地前提下，FPN对尺度信息进行了很好地弥补，而Focal loss则对区域地回归有一定辅助效果。</p><h3 id="anchor-free局限性"><a href="#anchor-free局限性" class="headerlink" title="anchor-free局限性"></a>anchor-free局限性</h3><p>当然，anchor-free地目标检测方法也有很大地局限性，这些方法虽然声称精度追上了较好地二阶段方法，但存在一些训练上地细节以及部分不公平地比较。不过，总体来说，速度上地突破还是吸引了很多工业界的关注的。</p><h3 id="GT的设计"><a href="#GT的设计" class="headerlink" title="GT的设计"></a>GT的设计</h3><p>上面的很多方法其实出发点都是bbox这个矩形框冗余信息太多，目标信息少，大部分是背景。它们大多都改变了GT的定义，如CornerNet将其定义为角点，ExtremeNet将其定义为极值点，FCOS虽然还是矩形框但也使用了center-ness进行抑制，FSAF则将GT定义为中心区域。对于GT目标的改进优化促使了目标检测的发展。</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><strong>Densebox</strong>: Huang L, Yang Y, Deng Y, et al. Densebox: Unifying landmark localization with end to end object detection[J]. arXiv preprint arXiv:1509.04874, 2015.<br><br><strong>YOLO</strong>: Redmon J, Divvala S, Girshick R, et al. You only look once: Unified, real-time object detection[A]. Proceedings of the IEEE conference on computer vision and pattern recognition[C]. 2016: 779–788.<br><br><strong>FCOS</strong>: Tian Z, Shen C, Chen H, et al. FCOS: Fully Convolutional One-Stage Object Detection[J]. arXiv:1904.01355 [cs], 2019.<br><br><strong>FSAF</strong>: Zhu C, He Y, Savvides M. Feature Selective Anchor-Free Module for Single-Shot Object Detection[J]. arXiv:1903.00621 [cs], 2019.<br><br><strong>CornerNet</strong>: Law H, Deng J. CornerNet: Detecting Objects as Paired Keypoints[J]. arXiv:1808.01244 [cs], 2019.<br><br><strong>ExtremeNet</strong>: Zhou X, Zhuo J, Krähenbühl P. Bottom-up Object Detection by Grouping Extreme and Center Points[J]. arXiv:1901.08043 [cs], 2019.<br><br><strong>CenterNet</strong>: Zhou X, Wang D, Krähenbühl P. Objects as points[A]. arXiv preprint arXiv:1904.07850[C]. 2019.</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 目标检测 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> anchor-free目标检测 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2020/08/19/hello-world/"/>
      <url>/2020/08/19/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><pre class=" language-bash"><code class="language-bash">$ hexo new <span class="token string">"My New Post"</span></code></pre><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><pre class=" language-bash"><code class="language-bash">$ hexo server</code></pre><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><pre class=" language-bash"><code class="language-bash">$ hexo generate</code></pre><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><pre class=" language-bash"><code class="language-bash">$ hexo deploy</code></pre><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
